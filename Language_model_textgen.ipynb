{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rai8U6Qs9fSG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM, Embedding, GRU\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import get_file, to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "import requests\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/language_model/internet_archive_scifi_v3.txt'"
      ],
      "metadata": {
        "id": "hUZfCOj09koe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(path, 'r').read()"
      ],
      "metadata": {
        "id": "US-kAsOT9unA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPr0zkdg9xio",
        "outputId": "0a5f4677-f817-409f-caa8-491025398da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149326361"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(file[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPTT9cm99zWB",
        "outputId": "dbfbaa03-3bf9-4fcb-bb0e-34d222936153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MARCH # All Stories New and Complete Publisher Editor IF is published bi-monthly by Quinn Publishing Company, Inc., Kingston, New York. Volume #, No. #. Copyright # by Quinn Publishing Company, Inc. Application for Entry' as Second Class matter at Post Office, Buffalo, New York, pending. Subscriptio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaned_text(text):\n",
        "  text = text.split(\" \")\n",
        "  text = re.sub(r'[^\\x00-\\x7f]', r'', str(text)) # removing special chars...\n",
        "  text = text.translate(str.maketrans('', '', string.punctuation)) # removing special chars...\n",
        "  text = re.sub('\\s+', ' ', str(text)) # removing extra spaces...\n",
        "  return text"
      ],
      "metadata": {
        "id": "RgXPyAPD9zya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = cleaned_text(file)"
      ],
      "metadata": {
        "id": "qNLuUR8i9-ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAv38DWK9--i",
        "outputId": "9563809d-e63d-4fc5-bbdf-04793617b8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142442755"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_corpus = text.split(\" \")\n",
        "text_corpus = [x for x in text_corpus if x != \"\"]\n",
        "unique_vocab = list(set(text_corpus))"
      ],
      "metadata": {
        "id": "ifuPZisH-Bda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPVqjJZ7-DZy",
        "outputId": "22d34443-718c-4bb4-8d48-7ea1a5b6db96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26308635"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(unique_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "espxGX5L-Gzy",
        "outputId": "d1e1a383-4080-48e6-c591-d6c83a745b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "330125"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length =  30\n",
        "step_size = 1 \n",
        "all_sentences = []\n",
        "for i in range(seq_length, len(text_corpus)):\n",
        "  sentence = text_corpus[i - seq_length: i] # sliding window, dividing the whole text into multiple strings, each of length 31...\n",
        "  sentence = ' '.join(sentence)\n",
        "  all_sentences.append(sentence)"
      ],
      "metadata": {
        "id": "r1mkAg9y-IdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BDToQoq-dDs",
        "outputId": "4d24e2c2-30de-4b6e-dfde-08b85626f59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MARCH All Stories New and Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for',\n",
              " 'All Stories New and Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry',\n",
              " 'Stories New and Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as',\n",
              " 'New and Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second',\n",
              " 'and Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class',\n",
              " 'Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class matter',\n",
              " 'Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class matter at',\n",
              " 'Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class matter at Post',\n",
              " 'IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class matter at Post Office',\n",
              " 'is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class matter at Post Office Buffalo']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NVqksYD-dIk",
        "outputId": "d0e66134-7968-4e27-f03e-3d44ee986dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26308605"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sent  = all_sentences[:500000]"
      ],
      "metadata": {
        "id": "NFO0TFMftA4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(model_sent)"
      ],
      "metadata": {
        "id": "QRLKM16Sv3as"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sent[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncMnUfuBv-fn",
        "outputId": "618900ad-3a53-4c58-dd00-16fd95f2fe8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MARCH All Stories New and Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for',\n",
              " 'All Stories New and Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry',\n",
              " 'Stories New and Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as',\n",
              " 'New and Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second',\n",
              " 'and Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class',\n",
              " 'Complete Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class matter',\n",
              " 'Publisher Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class matter at',\n",
              " 'Editor IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class matter at Post',\n",
              " 'IF is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class matter at Post Office',\n",
              " 'is published bimonthly by Quinn Publishing Company Inc Kingston New York Volume No Copyright by Quinn Publishing Company Inc Application for Entry as Second Class matter at Post Office Buffalo']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing the words; converting words to numerical values...\n",
        "tokenizer = Tokenizer(num_words= 10000)\n",
        "tokenizer.fit_on_texts(model_sent)\n",
        "seq = tokenizer.texts_to_sequences(model_sent)"
      ],
      "metadata": {
        "id": "0xkqr3fo-gfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Pad sequences to a fixed length of 30\n",
        "max_length = 30\n",
        "padded_sequences = pad_sequences(seq, maxlen=max_length, padding='pre', truncating='pre')\n",
        "\n"
      ],
      "metadata": {
        "id": "zrElZA8LmqNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.vstack(padded_sequences)"
      ],
      "metadata": {
        "id": "Z19CsqyTpXkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Converting one dimentional list to numpy ndarray...\n",
        "# data = np.array(seq)"
      ],
      "metadata": {
        "id": "WwDFpg2S-gml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using first 30 columns of each rows as features and 31st as target variable...\n",
        "X = data[:, :-1]\n",
        "y = data[:, -1]"
      ],
      "metadata": {
        "id": "auU8pRbu-gpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "2pqf0fh9-grd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c8fc95-9f4e-4177-8bc5-e4d23e4403bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26014"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfxFtmzV6mdy",
        "outputId": "d9057360-9409-4c47-f32f-8af8cb9edf37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout"
      ],
      "metadata": {
        "id": "kUdkX54z5kd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential LSTM model to predict next word...\n",
        "model = Sequential()\n",
        "\n",
        "# input_dim is the length of the vocab/dictionary that we created earlier, output_dim is 50, and input length is 31...\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 50, input_length = X.shape[1])) \n",
        "\n",
        "# 64 LSTM units and return_sequences = True to pass it on to next LSTM layer...\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "\n",
        "\n",
        "model.add(LSTM(64))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))"
      ],
      "metadata": {
        "id": "Gb7rvuOj-vt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "vQiyPK88zjiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7f5abc-a02a-4af5-c5da-f510da835f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 29, 50)            1300750   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 29, 64)            29440     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 26015)             3355935   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,727,469\n",
            "Trainable params: 4,727,469\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # define the checkpoint\n",
        "# filepath=\"/content/drive/MyDrive/textgen/weights.hdf5\"\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "# callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "bp9jE7DJ-vwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model with adam optimizer and training it for 200 epochs...\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define a filepath for the saved weights\n",
        "filepath = '/content/drive/MyDrive/language_model/model_weights.{epoch:03d}'\n",
        "\n",
        "# Define a callback to save the weights after each epoch\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', save_best_only=True, mode='min', verbose=1)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "lstm_history = model.fit(X, y, batch_size = 32, epochs=100 , callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "561SeDf5_Iaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# when input text and number of words to be generated are given... this function will return text...\n",
        "def text_generator(model, tokenizer, seq_len, feature_text, num_words):\n",
        "  text = []\n",
        "  for i in range(num_words):\n",
        "    token = tokenizer.texts_to_sequences([feature_text])[0]\n",
        "    token = pad_sequences([token], maxlen = seq_len, truncating='pre')\n",
        "    # y_pred = model.predict_classes(token)\n",
        "    y_pred = model.predict(token) \n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    pred_word = ''\n",
        "    for word, idx in tokenizer.word_index.items():\n",
        "      if idx == y_pred:\n",
        "        pred_word = word\n",
        "        break\n",
        "    feature_text += \" \"+ pred_word\n",
        "    text.append(pred_word)\n",
        "\n",
        "  return \" \".join(text)"
      ],
      "metadata": {
        "id": "Pci_z-oE0oKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**MODEL EVALUATION**"
      ],
      "metadata": {
        "id": "BR4aFN5Cg2s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/language_model/lstm.h5') # saving model..."
      ],
      "metadata": {
        "id": "Dj-bh7M41YAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = load_model('/content/drive/MyDrive/language_model/lstm.h5') # loading model..."
      ],
      "metadata": {
        "id": "EA2Xk-2V1c__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_words = 50 # number of words to be generated...\n",
        "\n",
        "# input text...\n",
        "text = \"\"\"He moved slowly and with a kind of painful dignity, as a man moves on his way to the firing squad. A rumpled shock of black hair pointed up the extreme pallor of a gaunt face\"\"\"\n",
        "\n",
        "text_generator(lstm_model, tokenizer, X.shape[1], text, num_of_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "gkiKFHKL0_nv",
        "outputId": "76029976-9e99-4dd1-a5d5-8225b36ab4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'days on that instantly on the really was item the couldnt or who youll the else you out did he you warily of singhalut the true huge almost left shrugged answer walked the knocked chairman to which against to with had possibility one miles after then from laugh and thousand'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p4UPsX_K4kKe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}